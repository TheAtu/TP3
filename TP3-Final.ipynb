{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt  \n",
    "import statsmodels.api as sm     \n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score,roc_curve, roc_auc_score, RocCurveDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'input/'\n",
    "output_dir = 'output/'\n",
    "EPHs_dir = input_dir + 'EPH_usu_1er_Trim_2023_xlsx/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1\n",
    "A continuación, complementamos el trabajo hecho en el TP2 usando [la encuesta a\n",
    "nivel hogares de la EPH](../input/EPH_usu_1er_Trim_2023_xlsx)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Exploren el diseño de registro de la base de hogar: a priori, ¿qué variables creen\n",
    "que pueden ser muy predictivas de pobreza y que sería muy útil incluir para\n",
    "perfeccionar el ejercicio del TP2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Descarguen la base de microdatos de la EPH correspondiente al primer trimestre\n",
    "de 2023 (la base de hogares se llama [usu_hogar_T123.xls](//input/EPH_usu_1er_Trim_2023_xlsx/usu_hogar_T123.xlsx)). Importen los datos\n",
    "de la encuesta de hogar y, al igual que en el TP2, conserven sólo las observaciones\n",
    "que corresponden a los aglomerados de Ciudad Autónoma de Buenos Aires o\n",
    "del Gran Buenos Aires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODUSU</th>\n",
       "      <th>ANO4</th>\n",
       "      <th>TRIMESTRE</th>\n",
       "      <th>NRO_HOGAR</th>\n",
       "      <th>REALIZADA</th>\n",
       "      <th>REGION</th>\n",
       "      <th>MAS_500</th>\n",
       "      <th>AGLOMERADO</th>\n",
       "      <th>PONDERA</th>\n",
       "      <th>IV1</th>\n",
       "      <th>...</th>\n",
       "      <th>GDECCFR</th>\n",
       "      <th>PDECCFR</th>\n",
       "      <th>ADECCFR</th>\n",
       "      <th>PONDIH</th>\n",
       "      <th>VII1_1</th>\n",
       "      <th>VII1_2</th>\n",
       "      <th>VII2_1</th>\n",
       "      <th>VII2_2</th>\n",
       "      <th>VII2_3</th>\n",
       "      <th>VII2_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TQRMNORVYHMOTSCDEIJAH00802517</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>1066</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TQRMNOSQRHLLTTCDEIJAH00719390</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>2270</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>4733</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TQSMNOSQRHLLTTCDEIJAH00719389</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>2161</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2672</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>TQRMNORTUHKOQQCDEIJAH00780489</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>3097</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>4844</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>TQRMNOUTRHKNQMCDEIJAH00802590</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>2571</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>3482</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>TQRMNOQQPHJMQUCDEIJAH00796386</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>1540</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>TQRMNOSXXHKMQNCDEIJAH00780852</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>350</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>753</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>TQRMNOPQXHLNQSCDEIJAH00719335</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>754</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1324</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>TQRMNORRRHLNQSCDEIJAH00780835</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>661</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1296</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>TQRMNOSPWHMMQTCDEIJAH00802591</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>1522</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>TQRMNOPRWHMNQUCDEIJAH00802592</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>852</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1258</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>TQRMNOPUUHMKRLCDEIJAH00802593</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>991</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>TQRMNORWWHMOTLCDEIJAH00802594</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>1945</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>6063</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>TQRMNOQTWHMLKSCDEIIAD00801862</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>32</td>\n",
       "      <td>2295</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>TQRMNOSQXHKKKRCDEIIAD00780078</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>32</td>\n",
       "      <td>777</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            CODUSU  ANO4  TRIMESTRE  NRO_HOGAR  REALIZADA  \\\n",
       "9    TQRMNORVYHMOTSCDEIJAH00802517  2023          1          1          1   \n",
       "10   TQRMNOSQRHLLTTCDEIJAH00719390  2023          1          1          1   \n",
       "11   TQSMNOSQRHLLTTCDEIJAH00719389  2023          1          1          1   \n",
       "35   TQRMNORTUHKOQQCDEIJAH00780489  2023          1          1          1   \n",
       "98   TQRMNOUTRHKNQMCDEIJAH00802590  2023          1          1          1   \n",
       "99   TQRMNOQQPHJMQUCDEIJAH00796386  2023          1          1          1   \n",
       "100  TQRMNOSXXHKMQNCDEIJAH00780852  2023          1          1          1   \n",
       "101  TQRMNOPQXHLNQSCDEIJAH00719335  2023          1          1          1   \n",
       "102  TQRMNORRRHLNQSCDEIJAH00780835  2023          1          1          1   \n",
       "103  TQRMNOSPWHMMQTCDEIJAH00802591  2023          1          1          1   \n",
       "104  TQRMNOPRWHMNQUCDEIJAH00802592  2023          1          1          1   \n",
       "105  TQRMNOPUUHMKRLCDEIJAH00802593  2023          1          1          1   \n",
       "115  TQRMNORWWHMOTLCDEIJAH00802594  2023          1          1          1   \n",
       "143  TQRMNOQTWHMLKSCDEIIAD00801862  2023          1          1          1   \n",
       "144  TQRMNOSQXHKKKRCDEIIAD00780078  2023          1          1          1   \n",
       "\n",
       "     REGION MAS_500  AGLOMERADO  PONDERA  IV1  ... GDECCFR  PDECCFR  ADECCFR  \\\n",
       "9         1       S          33     1066    1  ...    12.0      NaN       12   \n",
       "10        1       S          33     2270    2  ...     6.0      NaN        7   \n",
       "11        1       S          33     2161    1  ...     7.0      NaN        8   \n",
       "35        1       S          33     3097    1  ...     8.0      NaN        9   \n",
       "98        1       S          33     2571    1  ...     8.0      NaN        9   \n",
       "99        1       S          33     1540    1  ...    12.0      NaN       12   \n",
       "100       1       S          33      350    1  ...     1.0      NaN        1   \n",
       "101       1       S          33      754    1  ...     3.0      NaN        4   \n",
       "102       1       S          33      661    1  ...     2.0      NaN        2   \n",
       "103       1       S          33     1522    1  ...    12.0      NaN       12   \n",
       "104       1       S          33      852    1  ...     5.0      NaN        6   \n",
       "105       1       S          33      991    1  ...     8.0      NaN        9   \n",
       "115       1       S          33     1945    2  ...     6.0      NaN        6   \n",
       "143       1       S          32     2295    2  ...    12.0      NaN       12   \n",
       "144       1       S          32      777    2  ...    12.0      NaN       12   \n",
       "\n",
       "    PONDIH  VII1_1  VII1_2  VII2_1  VII2_2 VII2_3  VII2_4  \n",
       "9        0       1       0      98       0      0       0  \n",
       "10    4733       1       0       2       0      0       0  \n",
       "11    2672       1       0      98       0      0       0  \n",
       "35    4844       1       0      98       0      0       0  \n",
       "98    3482       1       0      97       0      0       0  \n",
       "99       0       1       0      98       0      0       0  \n",
       "100    753       2       0       3       6      0       0  \n",
       "101   1324       2       0      98       0      0       0  \n",
       "102   1296       2       0      98       0      0       0  \n",
       "103      0       1       0      98       0      0       0  \n",
       "104   1258       1       0      98       0      0       0  \n",
       "105   1389       1       0      97       0      0       0  \n",
       "115   6063       2       1       3       4      5       0  \n",
       "143      0       1       0       2       0      0       0  \n",
       "144      0       2       0       1       0      0       0  \n",
       "\n",
       "[15 rows x 88 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Determinamos el directorio de la base de microdatos de la EPH\n",
    "eph_hog_dir = os.path.join(EPHs_dir, 'usu_hogar_T123.xlsx')\n",
    "\n",
    "#Leemos y copiamos dicha base\n",
    "dataframe = pd.read_excel(eph_hog_dir)\n",
    "df_eph_hog = dataframe.copy()\n",
    "\n",
    "#Nos quedamos solo con las Obs de CABA y GBA (Aglomerados: 32, 33)\n",
    "df_eph_hog_BsAs = df_eph_hog[df_eph_hog['AGLOMERADO'].isin([32, 33])]\n",
    "\n",
    "#Testeamos si lo importamos correctamente:\n",
    "df_eph_hog_BsAs.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Unan la tabla de la encuesta individual con la de la encuesta de hogar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determinamos el directorio de la base de microdatos de la EPH\n",
    "eph_indiv_dir = os.path.join(EPHs_dir, 'usu_individual_T123.xlsx')\n",
    "\n",
    "#Leemos y copiamos dicha base\n",
    "dataframe = pd.read_excel(eph_indiv_dir)\n",
    "df_eph_indiv = dataframe.copy()\n",
    "df_eph_indiv = df_eph_indiv[df_eph_indiv['AGLOMERADO'].isin([32, 33])]\n",
    "\n",
    "#No hace falta filtrar por BsAs ya que con el match de codigo tmb lo hace\n",
    "df_eph_BsAs = pd.merge(df_eph_indiv, df_eph_hog, on=['CODUSU','NRO_HOGAR'], how='inner', suffixes=('_H', '_I')) #solo se queda con las rows que en ambas bases tienen el mismo CODUSU, 'right' lo haria con hogar y NaN faltantes\n",
    "\n",
    "#Testeamos si lo importamos correctamente:\n",
    "with pd.option_context('display.max_columns', None): #nos permite temporalmente sacar la restriccion al limite de cols\n",
    "  df_eph_BsAs.head(50) \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df_eph_BsAs.drop(df_eph_BsAs.filter(like='_I').columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Generen sus propias funciones para limpiar la base de datos o, si deciden utilizar funciones existentes en paquetes como numpy y pandas, mencionen cuáles usarán y de qué paquetes son."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_drop_if(drop_if_missings=False, other_criteria=[], df=merged_df):\n",
    "  #dropear si cualquier valor de la lista esta en la columna\n",
    "  if other_criteria:\n",
    "    columns_to_drop = [col for col in df.columns if df[col].isin(other_criteria).any()]\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "  \n",
    "  #dropear si hay missinings(valores vacios)\n",
    "  if drop_if_missings:\n",
    "    df.dropna(axis=1, inplace=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def drop_neg_obs(cols=[], df=merged_df):\n",
    "  #transformamos la columna a valores numericos por las dudas\n",
    "  df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "  #(Checko si es neg) => Chequeo si algun valor es negativo => If si = True => Iniverto todo con \"~\" y me quedo solo convalores positivos\n",
    "  df = df[~(df[cols] < 0).any(axis=1)]\n",
    "  return df\n",
    "\n",
    "def replace_rename_col(col=None, replace_dic={}, new_name=None, df=merged_df):\n",
    "  df[col] = df[col].replace(replace_dic)\n",
    "  if new_name:\n",
    "    df = df.rename(columns={col: new_name})\n",
    "  return df\n",
    "\n",
    "def categorical_to_dummy(col=None, dummy_names_dic={}, keep_old_col=False, df=merged_df):\n",
    "  #le agrega a las keys del diccionario la col+\"_\" como prefijo --> Nos permite ser mas robusto, por si hay valores que no estan en el diccionario, generandolas con nombre identificable igualmente\n",
    "  complete_dummy_names_dic = {col+ '_' + key: value for key, value in dummy_names_dic.items()}\n",
    "  #Genera las dummies a partir de los valores categoricos y renombra las dummies segun el diccionario dado\n",
    "  new_dummies = pd.get_dummies(df[col], prefix=col, dtype=int).rename(columns=complete_dummy_names_dic)\n",
    "  \n",
    "  #si keep_old_col = False => drop col vieja\n",
    "  if ~keep_old_col:\n",
    "      df = df.drop(columns=[col])\n",
    "\n",
    "  #le agrega las nuevas dummies al df\n",
    "  df = pd.concat([df, new_dummies], axis=1)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       65\n",
       "1       70\n",
       "2       36\n",
       "3       28\n",
       "4        9\n",
       "        ..\n",
       "7613    38\n",
       "7614     9\n",
       "7615    77\n",
       "7616    45\n",
       "7617    17\n",
       "Name: CH06, Length: 6388, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eph_BsAs_clean = merged_df.copy()\n",
    "\n",
    "df_eph_BsAs_clean['CH06']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Limpien la base de datos tomando criterios que hagan sentido, tanto para el tratamiento de valores faltantes, de outliers, como así también decidan qué va- riables categóricas y strings usarán y transfórmenlas de forma que haga sentido para los ejercicios siguientes. Justifiquen sus decisiones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "justificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ponyl\\AppData\\Local\\Temp\\ipykernel_6056\\907508624.py:46: DeprecationWarning: Bitwise inversion '~' on bool is deprecated. This returns the bitwise inversion of the underlying int object and is usually not what you expect from negating a bool. Use the 'not' operator for boolean negation or ~int(x) if you really want the bitwise inversion of the underlying int.\n",
      "  if ~keep_old_col:\n"
     ]
    }
   ],
   "source": [
    "#guardamos el df original por precausion\n",
    "df_eph_BsAs_clean = merged_df.copy()\n",
    "\n",
    "df_eph_BsAs_clean = drop_neg_obs(\n",
    "  cols=['CH06', 'P21', 'IPCF_H', 'ITF_H', 'PP08D1'], df=df_eph_BsAs_clean)\n",
    "\n",
    "df_eph_BsAs_clean = col_drop_if(\n",
    "  drop_if_missings=True,\n",
    "  other_criteria=[], \n",
    "  df=df_eph_BsAs_clean)\n",
    "\n",
    "df_eph_BsAs_clean = replace_rename_col(\n",
    "  col='MAS_500_H',\n",
    "  replace_dic={'S':1,'N':0},\n",
    "  new_name='MAS_500',\n",
    "  df=df_eph_BsAs_clean)\n",
    "  \n",
    "df_eph_BsAs_clean = categorical_to_dummy(\n",
    "  col='REGION_H', \n",
    "  dummy_names_dic={\n",
    "    '44':'is_Patagonia',\n",
    "    '40':'is_Noroeste'}, \n",
    "  df=df_eph_BsAs_clean)\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "  df_eph_BsAs_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CH06</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7613</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7614</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7615</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7616</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7617</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6388 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CH06\n",
       "0       65\n",
       "1       70\n",
       "2       36\n",
       "3       28\n",
       "4        9\n",
       "...    ...\n",
       "7613    38\n",
       "7614     9\n",
       "7615    77\n",
       "7616    45\n",
       "7617    17\n",
       "\n",
       "[6388 rows x 1 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[['CH06']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       1\n",
       "2       1\n",
       "3       2\n",
       "4       2\n",
       "       ..\n",
       "7613    2\n",
       "7614    1\n",
       "7615    2\n",
       "7616    2\n",
       "7617    1\n",
       "Name: CH04, Length: 6388, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eph_BsAs_clean['CH04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CODUSU         0\n",
       "ANO4_H         0\n",
       "TRIMESTRE_H    0\n",
       "NRO_HOGAR      0\n",
       "COMPONENTE     0\n",
       "              ..\n",
       "VII2_1         0\n",
       "VII2_2         0\n",
       "VII2_3         0\n",
       "VII2_4         0\n",
       "REGION_I_1     0\n",
       "Length: 151, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eph_BsAs_clean.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Presenten estadísticas descriptivas de cinco variables de la encuesta de hogar que ustedes creen que pueden ser relevantes para predecir pobreza. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Repitan el inciso 1.2.f del TP2 para construir la columna adulto equiv y la columna ad equiv hogar (pueden utilizar su código del TP2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la tabla de equivalencias necesarias eneréticas según edad y sexo\n",
    "equiv_energ = { \n",
    "  1 : { #si es 1 = Varón\n",
    "    (0, 0.99): 0.35, #0.35 es el valor de un varón menor a 1 año\n",
    "    (1, 1): 0.37,\n",
    "    (2, 2): 0.46,\n",
    "    (3, 3): 0.51,\n",
    "    (4, 4): 0.55,\n",
    "    (5, 5): 0.6,\n",
    "    (6, 6): 0.64,\n",
    "    (7, 7): 0.66,\n",
    "    (8, 8): 0.68,\n",
    "    (9, 9): 0.69,\n",
    "    (10, 10): 0.79,\n",
    "    (11, 11): 0.82,\n",
    "    (12, 12): 0.85,\n",
    "    (13, 13): 0.9,\n",
    "    (14, 14): 0.96,\n",
    "    (15, 15): 1,\n",
    "    (16, 16): 1.03,\n",
    "    (17, 17): 1.04,\n",
    "    (18, 29): 1.02,\n",
    "    (30, 45): 1,\n",
    "    (46, 60): 1,\n",
    "    (61, 75): 0.83,\n",
    "    (75, 200): 0.74\n",
    "  },\n",
    "  2 : { #si es 2 = Mujer\n",
    "    (0, 0.99): 0.35,\n",
    "    (1, 1): 0.37,\n",
    "    (2, 2): 0.46,\n",
    "    (3, 3): 0.51,\n",
    "    (4, 4): 0.55,\n",
    "    (5, 5): 0.6,\n",
    "    (6, 6): 0.64,\n",
    "    (7, 7): 0.66,\n",
    "    (8, 8): 0.68,\n",
    "    (9, 9): 0.69,\n",
    "    (10, 10): 0.7,\n",
    "    (11, 11): 0.72,\n",
    "    (12, 12): 0.74,\n",
    "    (13, 13): 0.76,\n",
    "    (14, 14): 0.76,\n",
    "    (15, 15): 0.77,\n",
    "    (16, 16): 0.77,\n",
    "    (17, 17): 0.77,\n",
    "    (18, 29): 0.76,\n",
    "    (30, 45): 0.77,\n",
    "    (46, 60): 0.76,\n",
    "    (61, 75): 0.67,\n",
    "    (75, 200): 0.63\n",
    "    }\n",
    "}\n",
    "\n",
    "#Función para calcular 'adulto_equiv' basado en la edad y el sexo\n",
    "def calculate_adulto_equiv(row):\n",
    "  age = row['Edad'] #Obterner valor de \"edad\" del la row del df\n",
    "  sex = row['CH04'] #Obterner valor de \"edad\" del la row del df\n",
    "  \n",
    "  if sex in equiv_energ: #Verificar,por las dudas, si el sexo está en el dic\n",
    "     # Loopear los rangos de edad y valores en el dic\n",
    "    for (start, end), value in equiv_energ[sex].items():\n",
    "        if start <= age <= end: \n",
    "            return value #Devolver el valor correcto, si la edad está en el rango\n",
    "  else: \n",
    "    print(f'Not found [age:{age}, sex:{sex}]')\n",
    "  \n",
    "  return 0 #devolver 0 como valor predeterminado\n",
    "\n",
    "df_eph_BsAs_clean.rename(columns={'CH06': 'Edad'}, inplace=True)\n",
    "\n",
    "df_eph_BsAs_clean['adulto_equiv'] = df_eph_BsAs_clean.apply( #guarda el resultado de la funcion\n",
    "    lambda row: calculate_adulto_equiv(row), axis=1)#Aplica calculate_adulto_equiv a cada fila del df\n",
    "\n",
    "#Obtener 'ad_equiv_hogar' para cada row del df con groupby y transform\n",
    "df_eph_BsAs_clean['ad_equiv_hogar'] = df_eph_BsAs_clean.groupby('CODUSU')['adulto_equiv'].transform('sum')\n",
    "#Por el problema: base2 & floating point -> redondeamos a 2 decimales(estandar en esta base de datos)\n",
    "df_eph_BsAs_clean['ad_equiv_hogar'] = df_eph_BsAs_clean['ad_equiv_hogar'].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Repitan el inciso 1.3 y 1.4 del TP2 para dividir la base en dos dataframes donde: uno conserve las personas que no reportaron ITF (dataframe llamado 2 respondieron) y otro conserve a las personas que no reportaron ITF (llama- do norespondieron). Además, agreguen a la base respondieron una colum- na llamada ingreso necesario que sea el producto de la canasta básica por ad equiv hogar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4181\n",
      "2207\n",
      "0        86056.5750\n",
      "1        86056.5750\n",
      "2       140559.0725\n",
      "3       140559.0725\n",
      "4       140559.0725\n",
      "           ...     \n",
      "7611    219157.4110\n",
      "7612    141132.7830\n",
      "7613    141132.7830\n",
      "7614    141132.7830\n",
      "7615     36143.7615\n",
      "Name: ingreso_necesario, Length: 4181, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ponyl\\AppData\\Local\\Temp\\ipykernel_6056\\4082595519.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  respondieron.loc[:,\"ingreso_necesario\"] = respondieron[\"ad_equiv_hogar\"] * 57371.05\n"
     ]
    }
   ],
   "source": [
    "# 1.3\n",
    "\n",
    "\n",
    "# Generamos una dummy llamada respondieron, si indicaron un ingreso mayor a 0 se les asigna un 1\n",
    "df_eph_BsAs_clean['respondieron'] = (df_eph_BsAs_clean['ITF_H'] > 0).astype(int)\n",
    "\n",
    "\n",
    "# Sumamos para ver cuanta gente respondio\n",
    "total_respondieron = df_eph_BsAs_clean['respondieron'].sum()\n",
    "\n",
    "print(total_respondieron)\n",
    "\n",
    "# Repetimos para los que no respondieron (es decir los que reportaron un ingreso = 0)\n",
    "\n",
    "df_eph_BsAs_clean['norespondieron'] = (df_eph_BsAs_clean['ITF_H'] == 0).astype(int)\n",
    "\n",
    "total_norespondieron = df_eph_BsAs_clean['norespondieron'].sum()\n",
    "\n",
    "print(total_norespondieron)\n",
    "\n",
    "# Creamos la base 'respondieron'\n",
    "\n",
    "respondieron = df_eph_BsAs_clean[df_eph_BsAs_clean['ITF_H'] > 0]\n",
    "\n",
    "# Creamos la base 'norespondieron'\n",
    "\n",
    "norespondieron = df_eph_BsAs_clean[df_eph_BsAs_clean['ITF_H']==0]\n",
    "\n",
    "# 1.4\n",
    "\n",
    "# Creamos una nueva variable llamada ingreso necesario, que contiene la operacion exigida por la consigna\n",
    "\n",
    "respondieron.loc[:,\"ingreso_necesario\"] = respondieron[\"ad_equiv_hogar\"] * 57371.05\n",
    "\n",
    "\n",
    "print(respondieron['ingreso_necesario'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Agreguen a la base respondieron una columna llamada pobre, que tome valor 1 si el ITF es menor al ingreso necesario que necesita esa familia y 0 en caso contrario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ponyl\\AppData\\Local\\Temp\\ipykernel_6056\\3251145518.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  respondieron['pobre'] = (respondieron['ITF_H'] < respondieron['ingreso_necesario']).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Creamos una nueva columna llamada pobre, que contiene un 1 si la persona tiene un ingreso menor al necesario\n",
    "\n",
    "respondieron['pobre'] = (respondieron['ITF_H'] < respondieron['ingreso_necesario']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. En el TP2 calcularon los individuos bajo la línea de pobreza. Sin embargo, cuando se habla de pobreza el número más utilizado es el de la tasa de hogares bajo la línea de pobreza. Para calcularlo, utilicen una sola observación por hogar y sumen el ponderador PONDIH que permite expandir la muestra de la EPH al total de la población que representa. ¿Cuál es la tasa de hogares bajo la línea de pobreza para el GBA? ¿Se asemeja al que reporta el INDEC en sus informes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1566\n",
      "0.3745515426931356\n"
     ]
    }
   ],
   "source": [
    "# Contamos la cantidad de pobres\n",
    "cantidad_pobres = respondieron['pobre'].sum()\n",
    "proporción_pobres = cantidad_pobres/len(respondieron['pobre'])\n",
    "\n",
    "print(cantidad_pobres)\n",
    "print(proporción_pobres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Escriban una función, llamada evalua metodo, que reciba como argumentos un modelo y los datos de entrenamiento y prueba (X train, y train, X test, y test). La función debe ajustar el modelo con los datos de entrenamiento y calcular las métricas que considere necesarias para esta problemática (de mínima, deben reportar la matriz de confusión, las curvas ROC y los valores de AUC y de accuracy score de cada método). El output de la función debe ser una colección con las métricas evaluadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2040523362.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[13], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    return matriz_confusion curva_ROC valores_AUC\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def evalua_metodo(modelo, X_train, X_test, Y_train, Y_test):\n",
    "    modelo.fit(X_train,Y_train)\n",
    "    y_pred_modelo = modelo.predict(X_train)[,;1]\n",
    "    matriz_confusion_modelo = confusion_matrix(Y_test, y_pred_modelo)\n",
    "    tn, fp , fn, tp = confusion_matrix(Y_test, y_pred_modelo).ravel()\n",
    "    specificity_modelo = tn / (tn+fn)\n",
    "    accuracy_modelo = accuracy_score(Y_test, y_pred_modelo)\n",
    "    recall_modelo = recall_score(Y_test, y_pred_modelo)\n",
    "    precision_modelo = tp/(tp + fp)\n",
    "    auc_modelo = roc_auc_score(Y_test, y_pred_lda )\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test, y_pred_modelo)\n",
    "    np.set_printoptions(suppress = True)\n",
    "    display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc_lda, estimator_name='Análisis discriminante lineal')\n",
    "    display.plot()  \n",
    "    plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "    plt.show() \n",
    "    \n",
    "#ver output colección de métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Escriban una función, llamada cross validation, que realice validación cru-\n",
    "zada con k iteraciones (k -fold CV), llamando a la función del inciso anterior en\n",
    "cada una, pero para las k distintas particiones. La función debe recibir como\n",
    "argumentos el modelo, el valor de k y un dataset (es decir, sólo X e y). Pueden\n",
    "ayudarse con la función KFold para generar las particiones necesarias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =\n",
    "y =\n",
    "K = \n",
    "def cross_validation(modelo, K, X, Y):\n",
    "    kf = KFold(n_splits=K, shuffle=True, random_state=100)\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):   \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        modelo = evalua_metodo(modelo, X_train, X_test, Y_train, Y_test)[1]    \n",
    "        ecms = ecms.append({\"modelo\": modelo, \"particion\": i, \"ecm\": ecm}, ignore_index=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Escriban una función, llamada evalua config que reciba una lista de configuraciones de hiperparámetros1 (los distintos valores a probar como hiper\n",
    "parámetros podrian codificarse en diccionarios de Python) y utilizando la función cross validation obtenga el error2 promedio para cada configuración.\n",
    "En scikit-learn, muchos métodos llaman penalty al método de regularización y C a la inversa\n",
    "del hiperparámetro λ.\n",
    "Utilicen la medición del error que prefieran. Una opción ser ́ıa el Error Cuadrático Medio.\n",
    "Finalmente, la función debe devolver la configuración que genere menor error3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparametros = #crear lista de landas posibles\n",
    "\n",
    "def evalua_config (hiperparametros, K, X, Y):\n",
    "    ret={}\n",
    "    for i in hiperparametros:\n",
    "        reg =  LogisticRegression(C=1/i, penalty=\"elasticnet\")\n",
    "        ecm=cross_validation(reg,k, X, Y)\n",
    "        ret[elem]= ecm\n",
    "\n",
    "\n",
    "    return min(ret, key=ret.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Escriban una función llamada evalua multiples metodos que les permita im-\n",
    "plementar los siguiente métodos con los hiperparámetros que ustedes elijan.\n",
    "Para la regresión log ́ıstica, asegúrense de que esta función utilice su función\n",
    "evalua config para optimizar el λ de la regularización. Finalmente, el output\n",
    "de la función debe ser una tabla donde las columnas sean las métricas que hayan\n",
    "evaluado (las que hayan incluido en la función evalua metodo) y las filas sean\n",
    "los modelos (con su configuración de hiperparámetros asociada) que hayan co-\n",
    "rrido. Asegúrense de que la tabla incluya una columna con nombre del modelo\n",
    "y el valor de los hiperparámetros/configuración:4\n",
    "Regresión log ́ıstica\n",
    "Análisis de discriminante lineal\n",
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_knn = 3 #usamos la misma cantidad de vecinos cercanos que la otra vez\n",
    "\n",
    "def evalua_multiples_metodos (K, X_train, X_test , Y_train, Y_test, X, Y):\n",
    "\n",
    "    modelos = ['Logit','knn','lda']\n",
    "\n",
    "    #landas= np.arange(0.01, landa_max,10).tolist() --> crear bien lista de landas posibles\n",
    "\n",
    "    matriz = pd.DataFrame(columns=[\"Modelo\", \"Hiperparametro\",\"Precisión\", \"AUC\", \"ECM\"])\n",
    "\n",
    "    for modelo in modelos:\n",
    "        if modelo == 'Logit':\n",
    "            hiperparametro_optimo = evalua_config(LogisticRegression, K , X, Y) #hiperparametro landa\n",
    "            metricas_log= evalua_metodo(modelo, X_train, X_test, Y_train, Y_test)\n",
    "            results = [modelo, hiperparametro_optimo, metricas_log['accuracy'][0], metricas_log['auc'][0], metricas_log['ecm'][0]]\n",
    "            matriz.loc[len(matriz)] = results\n",
    "\n",
    "        elif modelo =='knn':\n",
    "            metricas_kvc = evalua_metodo(KNeighborsClassifier(n_neighbors=3), X_train, X_test, Y_train, Y_test)\n",
    "            results = [modelo, k_knn, metricas_kvc['accuracy'][0], metricas_kvc['auc'][0], metricas_kvc['ecm'][0]]\n",
    "            matriz.loc[len(matriz)] = results\n",
    "\n",
    "        elif modelo == 'lda':\n",
    "            metricas_ad = evalua_metodo(LinearDiscriminantAnalysis(n_components=1), X_train, X_test, Y_train, Y_test)\n",
    "            results = [modelo, \"NA\", metricas_ad['accuracy'][0], metricas_ad['auc'][0], metricas_ad['ecm'][0]]\n",
    "            matriz.loc[len(matriz)] = results\n",
    "\n",
    "\n",
    "    return(matriz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Eliminen de ambas bases (respondieron, norespondieron) todas las variables\n",
    "relacionadas a ingresos (en el archivo Dise ̃no de bases y estructura ver las ca-\n",
    "tegor ́ıas: ingresos de la ocupaci ́on principal de los asalariados, ingresos de la\n",
    "ocupaci ́on principal, ingresos de otras ocupaciones, ingreso total individual, in-\n",
    "gresos no laborales, ingreso total familiar, ingreso per c ́apita familiar). Eliminen\n",
    "tambi ́en las columnas adulto equiv, ad equiv hogar e ingreso necesario.\n",
    "Establezcan a la variable pobre como su variable dependiente (vector y). El\n",
    "resto de las variables ser ́an las variables independientes (matriz X). Dependien-\n",
    "do de la funci ́on que usen, no se olviden de agregar la columna de 1 cuando sea\n",
    "necesario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Corran la funci ́on evalua multiples metodos con la base respondieron. En\n",
    "los pr ́oximos incisos profundizaremos en la tarea de regularizaci ́on, pero en este\n",
    "ejercicio prueben al menos un hiperpar ́ametro para regularizar y al menos un\n",
    "valor de λ.\n",
    "3Consejo: cuanto m ́as gen ́erica construyan la funci ́on, luego podr ́a ser utilizada en m ́as situacio-\n",
    "nes. Por ahora, la usaremos solo para buscar el λ  ́optimo cuando utilicemos regularizaci ́on.\n",
    "4Pista: para la regresi ́on log ́ıstica, cuando incluyan regularizaci ́on observen que deber ́an correr\n",
    "la funci ́on evalua metodo dos veces. Una para optimizar los hiperpar ́ametros (con un set de datos\n",
    "para train y otro para validaci ́on) y otra para obtener las m ́etricas con el hiperpar ́ametro  ́optimo\n",
    "(con un set de datos para train y otro para test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Expliquen c ́omo elegir ́ıan λ por validaci ́on cruzada. Detallen por qu ́e no usar ́ıan\n",
    "el conjunto de prueba (test) para su elecci ́on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. En validaci ́on cruzada, ¿cu ́al es el problema de usar un k muy peque ̃no y uno\n",
    "muy grande? Cuando k = n (con n el n ́umero de muestras), ¿cu ́antas veces se\n",
    "estima el modelo?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Realicen un barrido en λ = 10n con n ∈ {−5, −4, −3 . . . , +4, +5} y utilicen 10\n",
    "fold CV para elegir el λ  ́optimo en regresi ́on logistica con Ridge y con LASSO.\n",
    "¿Qu ́e λ seleccion ́o en cada caso? Generen box-plots mostrando la distribuci ́on\n",
    "del error de predicci ́on para cada λ. Cada box debe corresponder a un valor de λ\n",
    "y contener como observaciones el error medio de validaci ́on para cada partici ́on.\n",
    "Adem ́as, para la regularizaci ́on LASSO, genere un box-plot similar, pero ahora\n",
    "graficando la proporci ́on de variables ignoradas por el modelo en funci ́on de λ,\n",
    "es decir la proporci ́on de variables para las cuales el coeficiente asociado es cero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. En el caso del valor  ́optimo de λ para LASSO encontrado en el inciso anterior,\n",
    "¿qu ́e variables fueron descartadas? ¿Son las que hubieran esperado? ¿Tiene re-\n",
    "laci ́on con lo que respondieron en el inciso 1 de la Parte I?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Elijan alguno de los modelos de regresi ́on log ́ıstica donde hayan probado distin-\n",
    "tos parametros de regularizaci ́on y comenten: ¿Qu ́e m ́etodo de regularizaci ́on\n",
    "funcion ́o mejor Ridge o LASSO? Comenten mencionando el error cuadr ́atico\n",
    "medio (ECM).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. ¿Cu ́al de todos los m ́etodos evaluados predice mejor? ¿Con qu ́e hiperpar ́ame-\n",
    "tros? Justifiquen detalladamente utilizando las medidas de precisi ́on que cono-\n",
    "cen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Con el m ́etodo que seleccionaron, predigan qu ́e personas son pobres dentro de\n",
    "la base norespondieron. ¿Qu ́e proporci ́on de los hogares son pobres en esa\n",
    "submuestra?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('pyEnv-Tmp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c624079bdbcdf559a5caa27822ba1284677e01b949e217d00eab1893de7b1b76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
