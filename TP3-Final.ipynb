{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt  \n",
    "import statsmodels.api as sm     \n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score,roc_curve, roc_auc_score, RocCurveDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'input/'\n",
    "output_dir = 'output/'\n",
    "EPHs_dir = input_dir + 'EPH_usu_1er_Trim_2023_xlsx/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1\n",
    "A continuación, complementamos el trabajo hecho en el TP2 usando [la encuesta a\n",
    "nivel hogares de la EPH](../input/EPH_usu_1er_Trim_2023_xlsx)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Exploren el diseño de registro de la base de hogar: a priori, ¿qué variables creen\n",
    "que pueden ser muy predictivas de pobreza y que sería muy útil incluir para\n",
    "perfeccionar el ejercicio del TP2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Descarguen la base de microdatos de la EPH correspondiente al primer trimestre\n",
    "de 2023 (la base de hogares se llama [usu_hogar_T123.xls](//input/EPH_usu_1er_Trim_2023_xlsx/usu_hogar_T123.xlsx)). Importen los datos\n",
    "de la encuesta de hogar y, al igual que en el TP2, conserven sólo las observaciones\n",
    "que corresponden a los aglomerados de Ciudad Autónoma de Buenos Aires o\n",
    "del Gran Buenos Aires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODUSU</th>\n",
       "      <th>ANO4</th>\n",
       "      <th>TRIMESTRE</th>\n",
       "      <th>NRO_HOGAR</th>\n",
       "      <th>REALIZADA</th>\n",
       "      <th>REGION</th>\n",
       "      <th>MAS_500</th>\n",
       "      <th>AGLOMERADO</th>\n",
       "      <th>PONDERA</th>\n",
       "      <th>IV1</th>\n",
       "      <th>...</th>\n",
       "      <th>GDECCFR</th>\n",
       "      <th>PDECCFR</th>\n",
       "      <th>ADECCFR</th>\n",
       "      <th>PONDIH</th>\n",
       "      <th>VII1_1</th>\n",
       "      <th>VII1_2</th>\n",
       "      <th>VII2_1</th>\n",
       "      <th>VII2_2</th>\n",
       "      <th>VII2_3</th>\n",
       "      <th>VII2_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TQRMNORVYHMOTSCDEIJAH00802517</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>1066</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TQRMNOSQRHLLTTCDEIJAH00719390</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>2270</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>4733</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TQSMNOSQRHLLTTCDEIJAH00719389</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>2161</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2672</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>TQRMNORTUHKOQQCDEIJAH00780489</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>3097</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>4844</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>TQRMNOUTRHKNQMCDEIJAH00802590</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>2571</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>3482</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>TQRMNOQQPHJMQUCDEIJAH00796386</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>1540</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>TQRMNOSXXHKMQNCDEIJAH00780852</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>350</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>753</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>TQRMNOPQXHLNQSCDEIJAH00719335</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>754</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1324</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>TQRMNORRRHLNQSCDEIJAH00780835</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>661</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1296</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>TQRMNOSPWHMMQTCDEIJAH00802591</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>1522</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>TQRMNOPRWHMNQUCDEIJAH00802592</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>852</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1258</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>TQRMNOPUUHMKRLCDEIJAH00802593</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>991</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>TQRMNORWWHMOTLCDEIJAH00802594</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>1945</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>6063</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>TQRMNOQTWHMLKSCDEIIAD00801862</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>32</td>\n",
       "      <td>2295</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>TQRMNOSQXHKKKRCDEIIAD00780078</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>32</td>\n",
       "      <td>777</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            CODUSU  ANO4  TRIMESTRE  NRO_HOGAR  REALIZADA  \\\n",
       "9    TQRMNORVYHMOTSCDEIJAH00802517  2023          1          1          1   \n",
       "10   TQRMNOSQRHLLTTCDEIJAH00719390  2023          1          1          1   \n",
       "11   TQSMNOSQRHLLTTCDEIJAH00719389  2023          1          1          1   \n",
       "35   TQRMNORTUHKOQQCDEIJAH00780489  2023          1          1          1   \n",
       "98   TQRMNOUTRHKNQMCDEIJAH00802590  2023          1          1          1   \n",
       "99   TQRMNOQQPHJMQUCDEIJAH00796386  2023          1          1          1   \n",
       "100  TQRMNOSXXHKMQNCDEIJAH00780852  2023          1          1          1   \n",
       "101  TQRMNOPQXHLNQSCDEIJAH00719335  2023          1          1          1   \n",
       "102  TQRMNORRRHLNQSCDEIJAH00780835  2023          1          1          1   \n",
       "103  TQRMNOSPWHMMQTCDEIJAH00802591  2023          1          1          1   \n",
       "104  TQRMNOPRWHMNQUCDEIJAH00802592  2023          1          1          1   \n",
       "105  TQRMNOPUUHMKRLCDEIJAH00802593  2023          1          1          1   \n",
       "115  TQRMNORWWHMOTLCDEIJAH00802594  2023          1          1          1   \n",
       "143  TQRMNOQTWHMLKSCDEIIAD00801862  2023          1          1          1   \n",
       "144  TQRMNOSQXHKKKRCDEIIAD00780078  2023          1          1          1   \n",
       "\n",
       "     REGION MAS_500  AGLOMERADO  PONDERA  IV1  ... GDECCFR  PDECCFR  ADECCFR  \\\n",
       "9         1       S          33     1066    1  ...    12.0      NaN       12   \n",
       "10        1       S          33     2270    2  ...     6.0      NaN        7   \n",
       "11        1       S          33     2161    1  ...     7.0      NaN        8   \n",
       "35        1       S          33     3097    1  ...     8.0      NaN        9   \n",
       "98        1       S          33     2571    1  ...     8.0      NaN        9   \n",
       "99        1       S          33     1540    1  ...    12.0      NaN       12   \n",
       "100       1       S          33      350    1  ...     1.0      NaN        1   \n",
       "101       1       S          33      754    1  ...     3.0      NaN        4   \n",
       "102       1       S          33      661    1  ...     2.0      NaN        2   \n",
       "103       1       S          33     1522    1  ...    12.0      NaN       12   \n",
       "104       1       S          33      852    1  ...     5.0      NaN        6   \n",
       "105       1       S          33      991    1  ...     8.0      NaN        9   \n",
       "115       1       S          33     1945    2  ...     6.0      NaN        6   \n",
       "143       1       S          32     2295    2  ...    12.0      NaN       12   \n",
       "144       1       S          32      777    2  ...    12.0      NaN       12   \n",
       "\n",
       "    PONDIH  VII1_1  VII1_2  VII2_1  VII2_2 VII2_3  VII2_4  \n",
       "9        0       1       0      98       0      0       0  \n",
       "10    4733       1       0       2       0      0       0  \n",
       "11    2672       1       0      98       0      0       0  \n",
       "35    4844       1       0      98       0      0       0  \n",
       "98    3482       1       0      97       0      0       0  \n",
       "99       0       1       0      98       0      0       0  \n",
       "100    753       2       0       3       6      0       0  \n",
       "101   1324       2       0      98       0      0       0  \n",
       "102   1296       2       0      98       0      0       0  \n",
       "103      0       1       0      98       0      0       0  \n",
       "104   1258       1       0      98       0      0       0  \n",
       "105   1389       1       0      97       0      0       0  \n",
       "115   6063       2       1       3       4      5       0  \n",
       "143      0       1       0       2       0      0       0  \n",
       "144      0       2       0       1       0      0       0  \n",
       "\n",
       "[15 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Determinamos el directorio de la base de microdatos de la EPH\n",
    "eph_hog_dir = os.path.join(EPHs_dir, 'usu_hogar_T123.xlsx')\n",
    "\n",
    "#Leemos y copiamos dicha base\n",
    "dataframe = pd.read_excel(eph_hog_dir)\n",
    "df_eph_hog = dataframe.copy()\n",
    "\n",
    "#Nos quedamos solo con las Obs de CABA y GBA (Aglomerados: 32, 33)\n",
    "df_eph_hog_BsAs = df_eph_hog[df_eph_hog['AGLOMERADO'].isin([32, 33])]\n",
    "\n",
    "#Testeamos si lo importamos correctamente:\n",
    "df_eph_hog_BsAs.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Unan la tabla de la encuesta individual con la de la encuesta de hogar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determinamos el directorio de la base de microdatos de la EPH\n",
    "eph_indiv_dir = os.path.join(EPHs_dir, 'usu_individual_T123.xlsx')\n",
    "\n",
    "#Leemos y copiamos dicha base\n",
    "dataframe = pd.read_excel(eph_indiv_dir)\n",
    "df_eph_indiv = dataframe.copy()\n",
    "df_eph_indiv = df_eph_indiv[df_eph_indiv['AGLOMERADO'].isin([32, 33])]\n",
    "\n",
    "#No hace falta filtrar por BsAs ya que con el match de codigo tmb lo hace\n",
    "df_eph_BsAs = pd.merge(df_eph_indiv, df_eph_hog, on=['CODUSU','NRO_HOGAR'], how='inner', suffixes=('_H', '_I')) #solo se queda con las rows que en ambas bases tienen el mismo CODUSU, 'right' lo haria con hogar y NaN faltantes\n",
    "\n",
    "#Testeamos si lo importamos correctamente:\n",
    "with pd.option_context('display.max_columns', None): #nos permite temporalmente sacar la restriccion al limite de cols\n",
    "  df_eph_BsAs.head(50) \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df_eph_BsAs.drop(df_eph_BsAs.filter(like='_I').columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Generen sus propias funciones para limpiar la base de datos o, si deciden utilizar funciones existentes en paquetes como numpy y pandas, mencionen cuáles usarán y de qué paquetes son."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_drop_if(drop_if_missings=False, other_criteria=[], df=merged_df):\n",
    "  #dropear si cualquier valor de la lista esta en la columna\n",
    "  if other_criteria:\n",
    "    columns_to_drop = [col for col in df.columns if df[col].isin(other_criteria).any()]\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "  \n",
    "  #dropear si hay missinings(valores vacios)\n",
    "  if drop_if_missings:\n",
    "    df.dropna(axis=1, inplace=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def drop_neg_obs(cols=[], df=merged_df):\n",
    "  #transformamos la columna a valores numericos por las dudas\n",
    "  df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "  #(Checko si es neg) => Chequeo si algun valor es negativo => If si = True => Iniverto todo con \"~\" y me quedo solo convalores positivos\n",
    "  df = df[~(df[cols] < 0).any(axis=1)]\n",
    "  return df\n",
    "\n",
    "def replace_rename_col(col=None, replace_dic={}, new_name=None, df=merged_df):\n",
    "  df[col] = df[col].replace(replace_dic)\n",
    "  if new_name:\n",
    "    df = df.rename(columns={col: new_name})\n",
    "  return df\n",
    "\n",
    "def categorical_to_dummy(col=None, dummy_names_dic={}, keep_old_col=False, df=merged_df):\n",
    "  #le agrega a las keys del diccionario la col+\"_\" como prefijo --> Nos permite ser mas robusto, por si hay valores que no estan en el diccionario, generandolas con nombre identificable igualmente\n",
    "  complete_dummy_names_dic = {col+ '_' + key: value for key, value in dummy_names_dic.items()}\n",
    "  #Genera las dummies a partir de los valores categoricos y renombra las dummies segun el diccionario dado\n",
    "  new_dummies = pd.get_dummies(df[col], prefix=col, dtype=int).rename(columns=complete_dummy_names_dic)\n",
    "  \n",
    "  #si keep_old_col = False => drop col vieja\n",
    "  if ~keep_old_col:\n",
    "      df = df.drop(columns=[col])\n",
    "\n",
    "  #le agrega las nuevas dummies al df\n",
    "  df = pd.concat([df, new_dummies], axis=1)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       65\n",
       "1       70\n",
       "2       36\n",
       "3       28\n",
       "4        9\n",
       "        ..\n",
       "7614     9\n",
       "7615    77\n",
       "7616    45\n",
       "7617    17\n",
       "7618    26\n",
       "Name: CH06, Length: 7619, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eph_BsAs_clean = merged_df.copy()\n",
    "\n",
    "df_eph_BsAs_clean['CH06']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Limpien la base de datos tomando criterios que hagan sentido, tanto para el tratamiento de valores faltantes, de outliers, como así también decidan qué va- riables categóricas y strings usarán y transfórmenlas de forma que haga sentido para los ejercicios siguientes. Justifiquen sus decisiones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "justificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ponyl\\AppData\\Local\\Temp\\ipykernel_19232\\893562635.py:33: DeprecationWarning: Bitwise inversion '~' on bool is deprecated. This returns the bitwise inversion of the underlying int object and is usually not what you expect from negating a bool. Use the 'not' operator for boolean negation or ~int(x) if you really want the bitwise inversion of the underlying int.\n",
      "  if ~keep_old_col:\n"
     ]
    }
   ],
   "source": [
    "#guardamos el df original por precausion\n",
    "df_eph_BsAs_clean = merged_df.copy()\n",
    "\n",
    "df_eph_BsAs_clean = drop_neg_obs(\n",
    "  cols=['CH06', 'P21', 'IPCF_H', 'ITF_H', 'PP08D1'], df=df_eph_BsAs_clean)\n",
    "\n",
    "df_eph_BsAs_clean = col_drop_if(\n",
    "  drop_if_missings=True,\n",
    "  other_criteria=[], \n",
    "  df=df_eph_BsAs_clean)\n",
    "\n",
    "df_eph_BsAs_clean = replace_rename_col(\n",
    "  col='MAS_500_H',\n",
    "  replace_dic={'S':1,'N':0},\n",
    "  new_name='MAS_500',\n",
    "  df=df_eph_BsAs_clean)\n",
    "  \n",
    "df_eph_BsAs_clean = categorical_to_dummy(\n",
    "  col='REGION_H', \n",
    "  dummy_names_dic={\n",
    "    '44':'is_Patagonia',\n",
    "    '40':'is_Noroeste'}, \n",
    "  df=df_eph_BsAs_clean)\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "  df_eph_BsAs_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CH06</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7614</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7615</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7616</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7617</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7618</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7619 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CH06\n",
       "0       65\n",
       "1       70\n",
       "2       36\n",
       "3       28\n",
       "4        9\n",
       "...    ...\n",
       "7614     9\n",
       "7615    77\n",
       "7616    45\n",
       "7617    17\n",
       "7618    26\n",
       "\n",
       "[7619 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[['CH06']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       1\n",
       "2       1\n",
       "3       2\n",
       "4       2\n",
       "       ..\n",
       "7613    2\n",
       "7614    1\n",
       "7615    2\n",
       "7616    2\n",
       "7617    1\n",
       "Name: CH04, Length: 6388, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eph_BsAs_clean['CH04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CODUSU         0\n",
       "ANO4_H         0\n",
       "TRIMESTRE_H    0\n",
       "NRO_HOGAR      0\n",
       "COMPONENTE     0\n",
       "              ..\n",
       "VII2_1         0\n",
       "VII2_2         0\n",
       "VII2_3         0\n",
       "VII2_4         0\n",
       "REGION_H_1     0\n",
       "Length: 133, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eph_BsAs_clean.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Presenten estadísticas descriptivas de cinco variables de la encuesta de hogar que ustedes creen que pueden ser relevantes para predecir pobreza. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Repitan el inciso 1.2.f del TP2 para construir la columna adulto equiv y la columna ad equiv hogar (pueden utilizar su código del TP2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la tabla de equivalencias necesarias eneréticas según edad y sexo\n",
    "equiv_energ = { \n",
    "  1 : { #si es 1 = Varón\n",
    "    (0, 0.99): 0.35, #0.35 es el valor de un varón menor a 1 año\n",
    "    (1, 1): 0.37,\n",
    "    (2, 2): 0.46,\n",
    "    (3, 3): 0.51,\n",
    "    (4, 4): 0.55,\n",
    "    (5, 5): 0.6,\n",
    "    (6, 6): 0.64,\n",
    "    (7, 7): 0.66,\n",
    "    (8, 8): 0.68,\n",
    "    (9, 9): 0.69,\n",
    "    (10, 10): 0.79,\n",
    "    (11, 11): 0.82,\n",
    "    (12, 12): 0.85,\n",
    "    (13, 13): 0.9,\n",
    "    (14, 14): 0.96,\n",
    "    (15, 15): 1,\n",
    "    (16, 16): 1.03,\n",
    "    (17, 17): 1.04,\n",
    "    (18, 29): 1.02,\n",
    "    (30, 45): 1,\n",
    "    (46, 60): 1,\n",
    "    (61, 75): 0.83,\n",
    "    (75, 200): 0.74\n",
    "  },\n",
    "  2 : { #si es 2 = Mujer\n",
    "    (0, 0.99): 0.35,\n",
    "    (1, 1): 0.37,\n",
    "    (2, 2): 0.46,\n",
    "    (3, 3): 0.51,\n",
    "    (4, 4): 0.55,\n",
    "    (5, 5): 0.6,\n",
    "    (6, 6): 0.64,\n",
    "    (7, 7): 0.66,\n",
    "    (8, 8): 0.68,\n",
    "    (9, 9): 0.69,\n",
    "    (10, 10): 0.7,\n",
    "    (11, 11): 0.72,\n",
    "    (12, 12): 0.74,\n",
    "    (13, 13): 0.76,\n",
    "    (14, 14): 0.76,\n",
    "    (15, 15): 0.77,\n",
    "    (16, 16): 0.77,\n",
    "    (17, 17): 0.77,\n",
    "    (18, 29): 0.76,\n",
    "    (30, 45): 0.77,\n",
    "    (46, 60): 0.76,\n",
    "    (61, 75): 0.67,\n",
    "    (75, 200): 0.63\n",
    "    }\n",
    "}\n",
    "\n",
    "#Función para calcular 'adulto_equiv' basado en la edad y el sexo\n",
    "def calculate_adulto_equiv(row):\n",
    "  age = row['Edad'] #Obterner valor de \"edad\" del la row del df\n",
    "  sex = row['CH04'] #Obterner valor de \"edad\" del la row del df\n",
    "  \n",
    "  if sex in equiv_energ: #Verificar,por las dudas, si el sexo está en el dic\n",
    "     # Loopear los rangos de edad y valores en el dic\n",
    "    for (start, end), value in equiv_energ[sex].items():\n",
    "        if start <= age <= end: \n",
    "            return value #Devolver el valor correcto, si la edad está en el rango\n",
    "  else: \n",
    "    print(f'Not found [age:{age}, sex:{sex}]')\n",
    "  \n",
    "  return 0 #devolver 0 como valor predeterminado\n",
    "\n",
    "df_eph_BsAs_clean.rename(columns={'CH06': 'Edad'}, inplace=True)\n",
    "\n",
    "df_eph_BsAs_clean['adulto_equiv'] = df_eph_BsAs_clean.apply( #guarda el resultado de la funcion\n",
    "    lambda row: calculate_adulto_equiv(row), axis=1)#Aplica calculate_adulto_equiv a cada fila del df\n",
    "\n",
    "#Obtener 'ad_equiv_hogar' para cada row del df con groupby y transform\n",
    "df_eph_BsAs_clean['ad_equiv_hogar'] = df_eph_BsAs_clean.groupby('CODUSU')['adulto_equiv'].transform('sum')\n",
    "#Por el problema: base2 & floating point -> redondeamos a 2 decimales(estandar en esta base de datos)\n",
    "df_eph_BsAs_clean['ad_equiv_hogar'] = df_eph_BsAs_clean['ad_equiv_hogar'].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Repitan el inciso 1.3 y 1.4 del TP2 para dividir la base en dos dataframes donde: uno conserve las personas que no reportaron ITF (dataframe llamado 2 respondieron) y otro conserve a las personas que no reportaron ITF (llama- do norespondieron). Además, agreguen a la base respondieron una colum- na llamada ingreso necesario que sea el producto de la canasta básica por ad equiv hogar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4181\n",
      "2207\n",
      "0        86056.5750\n",
      "1        86056.5750\n",
      "2       140559.0725\n",
      "3       140559.0725\n",
      "4       140559.0725\n",
      "           ...     \n",
      "7611    219157.4110\n",
      "7612    141132.7830\n",
      "7613    141132.7830\n",
      "7614    141132.7830\n",
      "7615     36143.7615\n",
      "Name: ingreso_necesario, Length: 4181, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ponyl\\AppData\\Local\\Temp\\ipykernel_19232\\4082595519.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  respondieron.loc[:,\"ingreso_necesario\"] = respondieron[\"ad_equiv_hogar\"] * 57371.05\n"
     ]
    }
   ],
   "source": [
    "# 1.3\n",
    "\n",
    "\n",
    "# Generamos una dummy llamada respondieron, si indicaron un ingreso mayor a 0 se les asigna un 1\n",
    "df_eph_BsAs_clean['respondieron'] = (df_eph_BsAs_clean['ITF_H'] > 0).astype(int)\n",
    "\n",
    "\n",
    "# Sumamos para ver cuanta gente respondio\n",
    "total_respondieron = df_eph_BsAs_clean['respondieron'].sum()\n",
    "\n",
    "print(total_respondieron)\n",
    "\n",
    "# Repetimos para los que no respondieron (es decir los que reportaron un ingreso = 0)\n",
    "\n",
    "df_eph_BsAs_clean['norespondieron'] = (df_eph_BsAs_clean['ITF_H'] == 0).astype(int)\n",
    "\n",
    "total_norespondieron = df_eph_BsAs_clean['norespondieron'].sum()\n",
    "\n",
    "print(total_norespondieron)\n",
    "\n",
    "# Creamos la base 'respondieron'\n",
    "\n",
    "respondieron = df_eph_BsAs_clean[df_eph_BsAs_clean['ITF_H'] > 0]\n",
    "\n",
    "# Creamos la base 'norespondieron'\n",
    "\n",
    "norespondieron = df_eph_BsAs_clean[df_eph_BsAs_clean['ITF_H']==0]\n",
    "\n",
    "# 1.4\n",
    "\n",
    "# Creamos una nueva variable llamada ingreso necesario, que contiene la operacion exigida por la consigna\n",
    "\n",
    "respondieron.loc[:,\"ingreso_necesario\"] = respondieron[\"ad_equiv_hogar\"] * 57371.05\n",
    "\n",
    "\n",
    "print(respondieron['ingreso_necesario'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Agreguen a la base respondieron una columna llamada pobre, que tome valor 1 si el ITF es menor al ingreso necesario que necesita esa familia y 0 en caso contrario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ponyl\\AppData\\Local\\Temp\\ipykernel_19232\\3251145518.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  respondieron['pobre'] = (respondieron['ITF_H'] < respondieron['ingreso_necesario']).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Creamos una nueva columna llamada pobre, que contiene un 1 si la persona tiene un ingreso menor al necesario\n",
    "\n",
    "respondieron['pobre'] = (respondieron['ITF_H'] < respondieron['ingreso_necesario']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. En el TP2 calcularon los individuos bajo la línea de pobreza. Sin embargo, cuando se habla de pobreza el número más utilizado es el de la tasa de hogares bajo la línea de pobreza. Para calcularlo, utilicen una sola observación por hogar y sumen el ponderador PONDIH que permite expandir la muestra de la EPH al total de la población que representa. ¿Cuál es la tasa de hogares bajo la línea de pobreza para el GBA? ¿Se asemeja al que reporta el INDEC en sus informes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1566\n",
      "0.3745515426931356\n"
     ]
    }
   ],
   "source": [
    "# Contamos la cantidad de pobres\n",
    "cantidad_pobres = respondieron['pobre'].sum()\n",
    "proporción_pobres = cantidad_pobres/len(respondieron['pobre'])\n",
    "\n",
    "print(cantidad_pobres)\n",
    "print(proporción_pobres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from ISLP import load_data\n",
    "import os  \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt  \n",
    "import statsmodels.api as sm     \n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Escriban una función, llamada evalua metodo, que reciba como argumentos un modelo y los datos de entrenamiento y prueba (X train, y train, X test, y test). La función debe ajustar el modelo con los datos de entrenamiento y calcular las métricas que considere necesarias para esta problemática (de mínima, deben reportar la matriz de confusión, las curvas ROC y los valores de AUC y de accuracy score de cada método). El output de la función debe ser una colección con las métricas evaluadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalua_metodo(modelo, X_train, X_test, Y_train, Y_test):\n",
    "    modelo.fit(X_train, Y_train)\n",
    "    y_pred_modelo = modelo.predict(X_test)[:,1]\n",
    "    matriz_confusion_modelo = confusion_matrix(Y_test, y_pred_modelo)\n",
    "    tn, fp , fn, tp = confusion_matrix(Y_test, y_pred_modelo).ravel()\n",
    "    specificity_modelo = tn / (tn+fn)\n",
    "    accuracy_modelo = accuracy_score(Y_test, y_pred_modelo)\n",
    "    recall_modelo = recall_score(Y_test, y_pred_modelo)\n",
    "    precision_modelo = tp/(tp + fp)\n",
    "    auc_modelo = roc_auc_score(Y_test, y_pred_modelo)\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test, y_pred_modelo)\n",
    "    np.set_printoptions(suppress = True)\n",
    "    display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc_lda, estimator_name='Análisis discriminante lineal')\n",
    "    display.plot()  \n",
    "    plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "    plt.show() \n",
    "    return matriz_confusion_modelo, specificity_modelo, accuracy_modelo, recall_modelo, presicion_modelo, auc_modelo, \n",
    "    \n",
    "#ver output colección de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalua_metodo(modelo, X_train, X_test, Y_test, Y_train, delta, k_knn):\n",
    "    \n",
    "    if modelo == LogisticRegression:\n",
    "        y = LogisticRegression(C=1/delta).fit(X_train, Y_train)\n",
    "    elif modelo == LinearDiscriminantAnalysis:\n",
    "        y = LinearDiscriminantAnalysis().fit(X_train, Y_train)\n",
    "    elif modelo == KNeighborsClassifier:\n",
    "        y = KNeighborsClassifier(k_knn).fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = y.predict(X_test)\n",
    "    \n",
    "    matriz_confusion = confusion_matrix(Y_test, Y_pred)\n",
    "    curva_ROC = roc_auc_score(Y_test, Y_pred)\n",
    "    valores_AUC = accuracy_score(Y_test, Y_pred)\n",
    "    \n",
    "    return matriz_confusion,curva_ROC,valores_AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Escriban una función, llamada cross validation, que realice validación cru-\n",
    "zada con k iteraciones (k -fold CV), llamando a la función del inciso anterior en\n",
    "cada una, pero para las k distintas particiones. La función debe recibir como\n",
    "argumentos el modelo, el valor de k y un dataset (es decir, sólo X e y). Pueden\n",
    "ayudarse con la función KFold para generar las particiones necesarias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(modelo, K, X, Y):\n",
    "    kf = KFold(n_splits=K, shuffle=True, random_state=100)\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):   \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        modelo = evalua_metodo(modelo, X_train, X_test, Y_train, Y_test)[1]    \n",
    "        ecms = ecms.append({\"modelo\": modelo, \"particion\": i, \"ecm\": ecm}, ignore_index=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Escriban una función, llamada evalua config que reciba una lista de configuraciones de hiperparámetros1 (los distintos valores a probar como hiper\n",
    "parámetros podrian codificarse en diccionarios de Python) y utilizando la función cross validation obtenga el error2 promedio para cada configuración.\n",
    "En scikit-learn, muchos métodos llaman penalty al método de regularización y C a la inversa\n",
    "del hiperparámetro λ.\n",
    "Utilicen la medición del error que prefieran. Una opción ser ́ıa el Error Cuadrático Medio.\n",
    "Finalmente, la función debe devolver la configuración que genere menor error3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiperparametros = #crear lista de landas posibles\n",
    "\n",
    "def evalua_config (hiperparametros, K, X, Y):\n",
    "    ret={}\n",
    "    for i in hiperparametros:\n",
    "        reg =  LogisticRegression(C=1/i, penalty=\"elasticnet\")\n",
    "        ecm=cross_validation(reg,k, X, Y)\n",
    "        ret[elem]= ecm\n",
    "\n",
    "\n",
    "    return min(ret, key=ret.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Escriban una función llamada evalua multiples metodos que les permita im-\n",
    "plementar los siguiente métodos con los hiperparámetros que ustedes elijan.\n",
    "Para la regresión log ́ıstica, asegúrense de que esta función utilice su función\n",
    "evalua config para optimizar el λ de la regularización. Finalmente, el output\n",
    "de la función debe ser una tabla donde las columnas sean las métricas que hayan\n",
    "evaluado (las que hayan incluido en la función evalua metodo) y las filas sean\n",
    "los modelos (con su configuración de hiperparámetros asociada) que hayan co-\n",
    "rrido. Asegúrense de que la tabla incluya una columna con nombre del modelo\n",
    "y el valor de los hiperparámetros/configuración:4\n",
    "Regresión log ́ıstica\n",
    "Análisis de discriminante lineal\n",
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_knn = 3 #usamos la misma cantidad de vecinos cercanos que la otra vez\n",
    "\n",
    "def evalua_multiples_metodos (K, X_train, X_test , Y_train, Y_test, X, Y, hiperparametro_optimo, k_knn):\n",
    "\n",
    "    modelos = [LogisticRegression, KNeighborsClassifier, LinearDiscriminantAnalysis]\n",
    "\n",
    "    #landas= np.arange(0.01, landa_max,10).tolist() --> crear bien lista de landas posibles\n",
    "\n",
    "    matriz = pd.DataFrame(columns=[\"Modelo\", \"Hiperparametro\",\"Precisión\", \"AUC\", \"ECM\"])\n",
    "    for modelo in modelos:\n",
    "        if modelo == LogisticRegression:\n",
    "            hiperparametro_optimo = evalua_config(LogisticRegression, K, X, Y) #hiperparametro landa\n",
    "            metricas_log= evalua_metodo(modelo, X_train, X_test, Y_train, Y_test, hiperparametro_optimo, k_knn)\n",
    "            results = [modelo, hiperparametro_optimo, metricas_log['accuracy'][0], metricas_log['auc'][0], metricas_log['ecm'][0]]\n",
    "            matriz.loc[len(matriz)] = results\n",
    "\n",
    "        elif modelo == KNeighborsClassifier:\n",
    "            metricas_kvc = evalua_metodo(modelo, X_train, X_test, Y_train, Y_test, delta, k_knn)\n",
    "            results = [modelo, k_knn, metricas_kvc['accuracy'][0], metricas_kvc['auc'][0], metricas_kvc['ecm'][0]]\n",
    "            matriz.loc[len(matriz)] = results\n",
    "\n",
    "        elif modelo == LinearDiscriminantAnalysis:\n",
    "            metricas_ad = evalua_metodo(modelo, X_train, X_test, Y_train, Y_test, delta, k_knn)\n",
    "            results = [modelo, \"NA\", metricas_ad['accuracy'][0], metricas_ad['auc'][0], metricas_ad['ecm'][0]]\n",
    "            matriz.loc[len(matriz)] = results\n",
    "\n",
    "\n",
    "    return(matriz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Eliminen de ambas bases (respondieron, norespondieron) todas las variables\n",
    "relacionadas a ingresos (en el archivo Dise ̃no de bases y estructura ver las ca-\n",
    "tegor ́ıas: ingresos de la ocupaci ́on principal de los asalariados, ingresos de la\n",
    "ocupaci ́on principal, ingresos de otras ocupaciones, ingreso total individual, in-\n",
    "gresos no laborales, ingreso total familiar, ingreso per c ́apita familiar). Eliminen\n",
    "tambi ́en las columnas adulto equiv, ad equiv hogar e ingreso necesario.\n",
    "Establezcan a la variable pobre como su variable dependiente (vector y). El\n",
    "resto de las variables ser ́an las variables independientes (matriz X). Dependien-\n",
    "do de la funci ́on que usen, no se olviden de agregar la columna de 1 cuando sea\n",
    "necesario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay columnas con datos de tipo string en el DataFrame.\n"
     ]
    }
   ],
   "source": [
    "columnas_a_eliminar = ['PP06A', 'PP06C', 'PP06D', 'PP06E', 'PP06H', 'PP08D1', 'PP08D4', 'PP08F1', 'PP08F2', 'PP08J1', 'PP08J2', \n",
    "                       'PP08J3', 'P21', 'DECOCUR', 'IDECOCUR', 'RDECOCUR', 'GDECOCOCUR', 'PDECOCUR', 'ADECOCUR', 'PONDIIO', \n",
    "                       'TOT_P12', 'P47T', 'DECINDR', 'IDECINDR', 'RDECINDR', 'GDECINDR', 'PDECINDR', 'ADECINDR', 'ADECINDR', \n",
    "                       'PONDII', 'V2_M', 'V3_M', 'V4_M', 'V5_M', 'V8_M', 'V9_M', 'V10_M', 'V11_M', 'V12_M', 'T_VI', 'ITF',\n",
    "                       'DECIFR', 'IDECIFR', 'RDECIFR', 'GDECIFR', 'PDECIFR', 'ADECIFR', 'IPCF', 'DECCFR', 'IDECCFR', 'RDECCFR',\n",
    "                       'GDECCFR', 'PDECCFR', 'ADECCFR', 'PONDIH', 'adulto_equiv','ad_equiv_hogar','ingreso_necesario', 'CODUSU', 'CH05']\n",
    "\n",
    "#Reescribimos los dataframes con las variables que nos interesan\n",
    "columnas_a_mantener = [col for col in respondieron.columns if col not in columnas_a_eliminar]\n",
    "\n",
    "columnas_a_mantener2 = [col for col in norespondieron.columns if col not in columnas_a_eliminar]\n",
    "\n",
    "\n",
    "respondieron = respondieron[columnas_a_mantener]\n",
    "norespondieron = norespondieron[columnas_a_mantener2]\n",
    "\n",
    "string_columns = respondieron.select_dtypes(include=['object'])\n",
    "\n",
    "# Mostrar las columnas con datos de tipo string\n",
    "if not string_columns.empty:\n",
    "    print(\"Las siguientes columnas contienen datos de tipo string:\")\n",
    "    print(string_columns.columns)\n",
    "else:\n",
    "    print(\"No hay columnas con datos de tipo string en el DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Corran la funci ́on evalua multiples metodos con la base respondieron. En\n",
    "los pr ́oximos incisos profundizaremos en la tarea de regularizaci ́on, pero en este\n",
    "ejercicio prueben al menos un hiperpar ́ametro para regularizar y al menos un\n",
    "valor de λ.\n",
    "3Consejo: cuanto m ́as gen ́erica construyan la funci ́on, luego podr ́a ser utilizada en m ́as situacio-\n",
    "nes. Por ahora, la usaremos solo para buscar el λ  ́optimo cuando utilicemos regularizaci ́on.\n",
    "4Pista: para la regresi ́on log ́ıstica, cuando incluyan regularizaci ́on observen que deber ́an correr\n",
    "la funci ́on evalua metodo dos veces. Una para optimizar los hiperpar ́ametros (con un set de datos\n",
    "para train y otro para validaci ́on) y otra para obtener las m ́etricas con el hiperpar ́ametro  ́optimo\n",
    "(con un set de datos para train y otro para test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "7611    1\n",
       "7612    0\n",
       "7613    0\n",
       "7614    0\n",
       "7615    0\n",
       "Name: pobre, Length: 4181, dtype: int32"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = respondieron['pobre']\n",
    "X_int = respondieron.copy()\n",
    "\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2926, 1255]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mg:\\My Drive\\año 4 trabajos\\E337 Big Data\\TP3\\TP3-Final.ipynb Cell 50\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/a%C3%B1o%204%20trabajos/E337%20Big%20Data/TP3/TP3-Final.ipynb#Y113sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39madd_constant(X_int)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/a%C3%B1o%204%20trabajos/E337%20Big%20Data/TP3/TP3-Final.ipynb#Y113sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m X_train, X_test, Y_train, Y_test \u001b[39m=\u001b[39m train_test_split(X, Y, test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m, random_state\u001b[39m=\u001b[39m \u001b[39m211\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/My%20Drive/a%C3%B1o%204%20trabajos/E337%20Big%20Data/TP3/TP3-Final.ipynb#Y113sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(evalua_multiples_metodos(\u001b[39m5\u001b[39;49m, X_train, X_test , Y_train, Y_test, X, Y, \u001b[39m10\u001b[39;49m, \u001b[39m3\u001b[39;49m))\n",
      "\u001b[1;32mg:\\My Drive\\año 4 trabajos\\E337 Big Data\\TP3\\TP3-Final.ipynb Cell 50\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/a%C3%B1o%204%20trabajos/E337%20Big%20Data/TP3/TP3-Final.ipynb#Y113sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m modelo \u001b[39min\u001b[39;00m modelos:\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/a%C3%B1o%204%20trabajos/E337%20Big%20Data/TP3/TP3-Final.ipynb#Y113sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mif\u001b[39;00m modelo \u001b[39m==\u001b[39m LogisticRegression:\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/a%C3%B1o%204%20trabajos/E337%20Big%20Data/TP3/TP3-Final.ipynb#Y113sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39m#hiperparametro_optimo = evalua_config(LogisticRegression, K, X, Y) #hiperparametro landa\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/My%20Drive/a%C3%B1o%204%20trabajos/E337%20Big%20Data/TP3/TP3-Final.ipynb#Y113sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         metricas_log\u001b[39m=\u001b[39m evalua_metodo(modelo, X_train, X_test, Y_train, Y_test, delta, k_knn)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/a%C3%B1o%204%20trabajos/E337%20Big%20Data/TP3/TP3-Final.ipynb#Y113sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         results \u001b[39m=\u001b[39m [modelo, hiperparametro_optimo, metricas_log[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m], metricas_log[\u001b[39m'\u001b[39m\u001b[39mauc\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m], metricas_log[\u001b[39m'\u001b[39m\u001b[39mecm\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/a%C3%B1o%204%20trabajos/E337%20Big%20Data/TP3/TP3-Final.ipynb#Y113sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         matriz\u001b[39m.\u001b[39mloc[\u001b[39mlen\u001b[39m(matriz)] \u001b[39m=\u001b[39m results\n",
      "\u001b[1;32mg:\\My Drive\\año 4 trabajos\\E337 Big Data\\TP3\\TP3-Final.ipynb Cell 50\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/a%C3%B1o%204%20trabajos/E337%20Big%20Data/TP3/TP3-Final.ipynb#Y113sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevalua_metodo\u001b[39m(modelo, X_train, X_test, Y_test, Y_train, delta, k_knn):\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/a%C3%B1o%204%20trabajos/E337%20Big%20Data/TP3/TP3-Final.ipynb#Y113sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mif\u001b[39;00m modelo \u001b[39m==\u001b[39m LogisticRegression:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/My%20Drive/a%C3%B1o%204%20trabajos/E337%20Big%20Data/TP3/TP3-Final.ipynb#Y113sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         y \u001b[39m=\u001b[39m LogisticRegression(C\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m/\u001b[39;49mdelta)\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/a%C3%B1o%204%20trabajos/E337%20Big%20Data/TP3/TP3-Final.ipynb#Y113sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39melif\u001b[39;00m modelo \u001b[39m==\u001b[39m LinearDiscriminantAnalysis:\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/a%C3%B1o%204%20trabajos/E337%20Big%20Data/TP3/TP3-Final.ipynb#Y113sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         y \u001b[39m=\u001b[39m LinearDiscriminantAnalysis()\u001b[39m.\u001b[39mfit(X_train, Y_train)\n",
      "File \u001b[1;32mc:\\Users\\ponyl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ponyl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1208\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1206\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[1;32m-> 1208\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1209\u001b[0m     X,\n\u001b[0;32m   1210\u001b[0m     y,\n\u001b[0;32m   1211\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1212\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[0;32m   1213\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1214\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1215\u001b[0m )\n\u001b[0;32m   1216\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[1;32mc:\\Users\\ponyl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\ponyl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1164\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1146\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[0;32m   1162\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m-> 1164\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1166\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\ponyl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2926, 1255]"
     ]
    }
   ],
   "source": [
    "# Eliminamos pobre de respondieron para que no sea la variable a predecir y predictora a la vez. \n",
    "if 'pobre' in X_int.columns:\n",
    "    X_int = X_int.drop('pobre', axis=1) \n",
    "    \n",
    "#Agregamos la columna de unos.\n",
    "X = sm.add_constant(X_int)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state= 211)\n",
    "\n",
    "print(evalua_multiples_metodos(5, X_train, X_test , Y_train, Y_test, X, Y, 10, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANO4_H</th>\n",
       "      <th>TRIMESTRE_H</th>\n",
       "      <th>NRO_HOGAR</th>\n",
       "      <th>COMPONENTE</th>\n",
       "      <th>H15</th>\n",
       "      <th>MAS_500</th>\n",
       "      <th>AGLOMERADO_H</th>\n",
       "      <th>PONDERA_H</th>\n",
       "      <th>CH03</th>\n",
       "      <th>CH04</th>\n",
       "      <th>...</th>\n",
       "      <th>IX_MAYEQ10</th>\n",
       "      <th>VII1_1</th>\n",
       "      <th>VII1_2</th>\n",
       "      <th>VII2_1</th>\n",
       "      <th>VII2_2</th>\n",
       "      <th>VII2_3</th>\n",
       "      <th>VII2_4</th>\n",
       "      <th>REGION_H_1</th>\n",
       "      <th>respondieron</th>\n",
       "      <th>norespondieron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1545</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1545</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>8423</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>8423</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>8423</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>3232</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7613</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1236</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7614</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1236</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7615</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1300</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4181 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ANO4_H  TRIMESTRE_H  NRO_HOGAR  COMPONENTE  H15  MAS_500  AGLOMERADO_H  \\\n",
       "0       2023            1          1           1    1        1            33   \n",
       "1       2023            1          1           2    1        1            33   \n",
       "2       2023            1          1           1    1        1            33   \n",
       "3       2023            1          1           2    1        1            33   \n",
       "4       2023            1          1           3    0        1            33   \n",
       "...      ...          ...        ...         ...  ...      ...           ...   \n",
       "7611    2023            1          1           5    0        1            33   \n",
       "7612    2023            1          1           1    1        1            33   \n",
       "7613    2023            1          1           2    1        1            33   \n",
       "7614    2023            1          1           3    0        1            33   \n",
       "7615    2023            1          1           1    1        1            33   \n",
       "\n",
       "      PONDERA_H  CH03  CH04  ...  IX_MAYEQ10  VII1_1  VII1_2  VII2_1  VII2_2  \\\n",
       "0          1545     1     2  ...           2       1       0       2       0   \n",
       "1          1545     2     1  ...           2       1       0       2       0   \n",
       "2          8423     1     1  ...           2       2       1      98       0   \n",
       "3          8423     2     2  ...           2       2       1      98       0   \n",
       "4          8423     3     2  ...           2       2       1      98       0   \n",
       "...         ...   ...   ...  ...         ...     ...     ...     ...     ...   \n",
       "7611       3232     3     1  ...           3       1       0       3       4   \n",
       "7612       1236     1     1  ...           2       1       2      98       0   \n",
       "7613       1236     2     2  ...           2       1       2      98       0   \n",
       "7614       1236     3     1  ...           2       1       2      98       0   \n",
       "7615       1300     1     2  ...           1       1       0      96       0   \n",
       "\n",
       "      VII2_3  VII2_4  REGION_H_1  respondieron  norespondieron  \n",
       "0          0       0           1             1               0  \n",
       "1          0       0           1             1               0  \n",
       "2          0       0           1             1               0  \n",
       "3          0       0           1             1               0  \n",
       "4          0       0           1             1               0  \n",
       "...      ...     ...         ...           ...             ...  \n",
       "7611       0       0           1             1               0  \n",
       "7612       0       0           1             1               0  \n",
       "7613       0       0           1             1               0  \n",
       "7614       0       0           1             1               0  \n",
       "7615       0       0           1             1               0  \n",
       "\n",
       "[4181 rows x 112 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Expliquen c ́omo elegir ́ıan λ por validaci ́on cruzada. Detallen por qu ́e no usar ́ıan\n",
    "el conjunto de prueba (test) para su elecci ́on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. En validaci ́on cruzada, ¿cu ́al es el problema de usar un k muy peque ̃no y uno\n",
    "muy grande? Cuando k = n (con n el n ́umero de muestras), ¿cu ́antas veces se\n",
    "estima el modelo?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Realicen un barrido en λ = 10n con n ∈ {−5, −4, −3 . . . , +4, +5} y utilicen 10\n",
    "fold CV para elegir el λ  ́optimo en regresi ́on logistica con Ridge y con LASSO.\n",
    "¿Qu ́e λ seleccion ́o en cada caso? Generen box-plots mostrando la distribuci ́on\n",
    "del error de predicci ́on para cada λ. Cada box debe corresponder a un valor de λ\n",
    "y contener como observaciones el error medio de validaci ́on para cada partici ́on.\n",
    "Adem ́as, para la regularizaci ́on LASSO, genere un box-plot similar, pero ahora\n",
    "graficando la proporci ́on de variables ignoradas por el modelo en funci ́on de λ,\n",
    "es decir la proporci ́on de variables para las cuales el coeficiente asociado es cero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. En el caso del valor  ́optimo de λ para LASSO encontrado en el inciso anterior,\n",
    "¿qu ́e variables fueron descartadas? ¿Son las que hubieran esperado? ¿Tiene re-\n",
    "laci ́on con lo que respondieron en el inciso 1 de la Parte I?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Elijan alguno de los modelos de regresi ́on log ́ıstica donde hayan probado distin-\n",
    "tos parametros de regularizaci ́on y comenten: ¿Qu ́e m ́etodo de regularizaci ́on\n",
    "funcion ́o mejor Ridge o LASSO? Comenten mencionando el error cuadr ́atico\n",
    "medio (ECM).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. ¿Cu ́al de todos los m ́etodos evaluados predice mejor? ¿Con qu ́e hiperpar ́ame-\n",
    "tros? Justifiquen detalladamente utilizando las medidas de precisi ́on que cono-\n",
    "cen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Con el m ́etodo que seleccionaron, predigan qu ́e personas son pobres dentro de\n",
    "la base norespondieron. ¿Qu ́e proporci ́on de los hogares son pobres en esa\n",
    "submuestra?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('pyEnv-Tmp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c624079bdbcdf559a5caa27822ba1284677e01b949e217d00eab1893de7b1b76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
